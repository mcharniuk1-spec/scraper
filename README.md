# Web Scraper Project

–ú–æ–¥—É–ª—å–Ω–∏–π –ø—Ä–æ—î–∫—Ç –¥–ª—è —Å–∫—Ä–∞–ø—ñ–Ω–≥—É –ø—Ä–æ–¥—É–∫—Ç—ñ–≤ –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω—ñ–≤ (Fora.ua —Ç–∞ Novus Zakaz.ua). –ü—Ä–æ—î–∫—Ç –≤–∫–ª—é—á–∞—î –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –ø–ª–∞–Ω—É–≤–∞–Ω–Ω—è, –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ç–∞ –∞–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –∑ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏–º –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è–º —Ü—ñ–Ω.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ—î–∫—Ç—É

```
scraper/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ historical_db.py    # –ú–æ–¥—É–ª—å –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —ñ—Å—Ç–æ—Ä–∏—á–Ω–æ—é –ë–î
‚îÇ   ‚îî‚îÄ‚îÄ scrapers/
‚îÇ       ‚îú‚îÄ‚îÄ base_scraper.py     # –ë–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –≤—Å—ñ—Ö —Å–∫—Ä–∞–ø–µ—Ä—ñ–≤
‚îÇ       ‚îú‚îÄ‚îÄ fora_scraper.py     # –°–∫—Ä–∞–ø–µ—Ä –¥–ª—è Fora.ua
‚îÇ       ‚îî‚îÄ‚îÄ novus_scraper.py    # –°–∫—Ä–∞–ø–µ—Ä –¥–ª—è Novus Zakaz.ua
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ fora.json               # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è Fora
‚îÇ   ‚îî‚îÄ‚îÄ novus.json              # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è Novus
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ run_scraper.py          # –ì–æ–ª–æ–≤–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫—É —Å–∫—Ä–∞–ø–µ—Ä—ñ–≤
‚îÇ   ‚îú‚îÄ‚îÄ monitor.py              # –°–∫—Ä–∏–ø—Ç –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –ø—Ä–æ–≥—Ä–µ—Å—É
‚îÇ   ‚îî‚îÄ‚îÄ analyze.py              # –°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª—ñ–∑—É —Ç–∞ –µ–∫—Å–ø–æ—Ä—Ç—É –¥–∞–Ω–∏—Ö
‚îú‚îÄ‚îÄ data/                       # –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –¥–∞–Ω–∏—Ö (–ë–î, Excel, –ª–æ–≥–∏)
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ scrape.yml          # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∑–∞–ø—É—Å–∫ –∫–æ–∂–Ω—ñ 12 –≥–æ–¥–∏–Ω
‚îÇ       ‚îî‚îÄ‚îÄ manual_scrape.yml   # –†—É—á–Ω–∏–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ GitHub Actions
‚îú‚îÄ‚îÄ requirements.txt            # –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ Python
‚îî‚îÄ‚îÄ README.md                   # –¶–µ–π —Ñ–∞–π–ª
```

## –ú–æ–∂–ª–∏–≤–æ—Å—Ç—ñ

- ‚úÖ –ú–æ–¥—É–ª—å–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –∑ –±–∞–∑–æ–≤–∏–º –∫–ª–∞—Å–æ–º –¥–ª—è —Å–∫—Ä–∞–ø–µ—Ä—ñ–≤
- ‚úÖ –Ü—Å—Ç–æ—Ä–∏—á–Ω–∞ –±–∞–∑–∞ –¥–∞–Ω–∏—Ö –∑ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è–º –∑–º—ñ–Ω —Ü—ñ–Ω
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –ø–ª–∞–Ω—É–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ GitHub Actions
- ‚úÖ –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—É —Å–∫—Ä–∞–ø—ñ–Ω–≥—É
- ‚úÖ –ï–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–∏—Ö —É JSON, CSV, Excel
- ‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–º—ñ–Ω —Ü—ñ–Ω
- ‚úÖ –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ robots.txt
- ‚úÖ –ü–æ–≤—Ç–æ—Ä–Ω—ñ —Å–ø—Ä–æ–±–∏ –ø—Ä–∏ –ø–æ–º–∏–ª–∫–∞—Ö
- ‚úÖ –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —á–µ—Ä–µ–∑ JSON —Ñ–∞–π–ª–∏

## –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è

1. –ö–ª–æ–Ω—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π:
```bash
git clone <repository-url>
cd scraper
```

2. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ:
```bash
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ pip3 –Ω–∞ macOS/Linux
pip3 install -r requirements.txt

# –ê–±–æ pip –Ω–∞ Windows
pip install -r requirements.txt

# –Ø–∫—â–æ –≤–∏–Ω–∏–∫–∞—é—Ç—å –ø—Ä–æ–±–ª–µ–º–∏ –∑ –ø—Ä–∞–≤–∞–º–∏ –¥–æ—Å—Ç—É–ø—É
pip install --user -r requirements.txt
```

3. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è:
```bash
python3 -c "import requests, bs4, backoff, pandas; print('–í—Å—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ!')"
```

4. –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–∞—Ç–∞–ª–æ–≥—ñ–≤ —Å—Ç–≤–æ—Ä–µ–Ω–∞:
```bash
mkdir -p data config
```

> **–ü—Ä–∏–º—ñ—Ç–∫–∞**: –î–µ—Ç–∞–ª—å–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –∑ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–∞ –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º –¥–∏–≤. –≤ [INSTALL.md](INSTALL.md)

## –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

### üöÄ –£–Ω—ñ—Ñ—ñ–∫–æ–≤–∞–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)

–ó–∞–ø—É—Å–∫ –æ–±–æ—Ö —Å–∫—Ä–∞–ø–µ—Ä—ñ–≤ –æ–¥–Ω–æ—á–∞—Å–Ω–æ –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –µ–∫—Å–ø–æ—Ä—Ç–æ–º —É Excel:

```bash
# –ó–∞–ø—É—Å–∫ –æ–±–æ—Ö —Å–∫—Ä–∞–ø–µ—Ä—ñ–≤ (Fora + Novus)
python3 scripts/run_all_scrapers.py

# –ó –æ–±–º–µ–∂–µ–Ω–Ω—è–º —Å—Ç–æ—Ä—ñ–Ω–æ–∫ (–¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)
python3 scripts/run_all_scrapers.py --max-pages 2

# –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –æ–¥–∏–Ω –∑—ñ —Å–∫—Ä–∞–ø–µ—Ä—ñ–≤
python3 scripts/run_all_scrapers.py --skip-fora
python3 scripts/run_all_scrapers.py --skip-novus
```

–ö–æ–º–∞–Ω–¥–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ:
- –ó–∞–ø—É—Å–∫–∞—î –æ–±–∏–¥–≤–∞ —Å–∫—Ä–∞–ø–µ—Ä–∏
- –ü–æ–∫–∞–∑—É—î –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ–¥—É–∫—Ç—ñ–≤
- –ï–∫—Å–ø–æ—Ä—Ç—É—î –¥–∞–Ω—ñ —É Excel —Ñ–∞–π–ª (`data/all_listings.xlsx`)
- –í–∏–≤–æ–¥–∏—Ç—å –ø—ñ–¥—Å—É–º–∫–æ–≤—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É

### –ó–∞–ø—É—Å–∫ –æ–∫—Ä–µ–º–æ–≥–æ —Å–∫—Ä–∞–ø–µ—Ä–∞

–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–µ—Ä–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∞–π—Ç—É:

```bash
# Fora
python3 scripts/run_scraper.py --site fora

# Novus
python3 scripts/run_scraper.py --site novus
```

–î–æ–¥–∞—Ç–∫–æ–≤—ñ –æ–ø—Ü—ñ—ó:

```bash
# –ó –æ–±–º–µ–∂–µ–Ω–Ω—è–º –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Å—Ç–æ—Ä—ñ–Ω–æ–∫
python3 scripts/run_scraper.py --site fora --max-pages 5

# –ó –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –≤–ª–∞—Å–Ω–æ–≥–æ –∫–æ–Ω—Ñ—ñ–≥—É
python3 scripts/run_scraper.py --site fora --config config/custom_fora.json

# –ó –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –≤–ª–∞—Å–Ω–æ—ó –ë–î
python3 scripts/run_scraper.py --site fora --db data/custom.db

# –¢–∏—Ö–∏–π —Ä–µ–∂–∏–º (–º–µ–Ω—à–µ –ª–æ–≥—ñ–≤)
python3 scripts/run_scraper.py --site fora --quiet
```

### –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥

–ü–µ—Ä–µ–≥–ª—è–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:

```bash
# –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
python3 scripts/monitor.py

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∞–π—Ç—É
python3 scripts/monitor.py --site fora

# –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É —É —Ñ–∞–π–ª
python3 scripts/monitor.py --site fora --log-progress
```

### –ê–Ω–∞–ª—ñ–∑ —Ç–∞ –µ–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–∏—Ö

–ï–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–∏—Ö:

```bash
# –ï–∫—Å–ø–æ—Ä—Ç —É Excel
python3 scripts/analyze.py --export-excel data/listings.xlsx

# –ï–∫—Å–ø–æ—Ä—Ç —É JSON
python3 scripts/analyze.py --export-json data/listings.json

# –ï–∫—Å–ø–æ—Ä—Ç —É CSV
python3 scripts/analyze.py --export-csv data/listings.csv

# –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ —Å–∞–π—Ç–æ–º
python3 scripts/analyze.py --site fora --export-excel data/fora_listings.xlsx
```

–ê–Ω–∞–ª—ñ–∑ –∑–º—ñ–Ω —Ü—ñ–Ω:

```bash
# –ê–Ω–∞–ª—ñ–∑ –∑–º—ñ–Ω —Ü—ñ–Ω
python3 scripts/analyze.py --analyze-prices

# –ê–Ω–∞–ª—ñ–∑ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∞–π—Ç—É
python3 scripts/analyze.py --site fora --analyze-prices
```

## –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

–ö–æ–∂–µ–Ω —Å–∞–π—Ç –º–∞—î —Å–≤—ñ–π –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏–π —Ñ–∞–π–ª —É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó `config/`:

### config/fora.json
```json
{
  "base_url": "https://fora.ua",
  "start_url": "https://fora.ua/category/molochni-produkty-ta-iaitsia-2656",
  "user_agent": "fora-scraper/1.0",
  "timeout": 20,
  "sleep_between_requests": 1.0,
  "max_retries": 5,
  "max_pages": 0,
  "site": "fora",
  "category": "molochni-produkty-ta-iaitsia"
}
```

### config/novus.json
```json
{
  "base_url": "https://novus.zakaz.ua",
  "start_url": "https://novus.zakaz.ua/uk/categories/dairy-and-eggs/",
  "user_agent": "novus-scraper/1.0",
  "timeout": 20,
  "sleep_between_requests": 0.5,
  "max_retries": 5,
  "max_pages": 0,
  "site": "novus",
  "category": "dairy-and-eggs"
}
```

## –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö

–ü—Ä–æ—î–∫—Ç –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î SQLite –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö. –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö –º—ñ—Å—Ç–∏—Ç—å:

- **listings** - –æ—Å–Ω–æ–≤–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –∑ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è–º–∏
- **price_history** - —ñ—Å—Ç–æ—Ä—ñ—è –∑–º—ñ–Ω —Ü—ñ–Ω

–ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –±–∞–∑–∞ –¥–∞–Ω–∏—Ö –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è —É `data/listings.db`.

## GitHub Actions

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∑–∞–ø—É—Å–∫

Workflow `scrape.yml` –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–∞–ø—É—Å–∫–∞—î —Å–∫—Ä–∞–ø–µ—Ä–∏ –∫–æ–∂–Ω—ñ 12 –≥–æ–¥–∏–Ω —Ç–∞ –∫–æ–º—ñ—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π.

### –†—É—á–Ω–∏–π –∑–∞–ø—É—Å–∫

Workflow `manual_scrape.yml` –¥–æ–∑–≤–æ–ª—è—î –∑–∞–ø—É—Å–∫–∞—Ç–∏ —Å–∫—Ä–∞–ø–µ—Ä–∏ –≤—Ä—É—á–Ω—É —á–µ—Ä–µ–∑ GitHub Actions UI –∑ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—é –≤–∏–±–æ—Ä—É —Å–∞–π—Ç—É —Ç–∞ –æ–±–º–µ–∂–µ–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Å—Ç–æ—Ä—ñ–Ω–æ–∫.

## –†–æ–∑—Ä–æ–±–∫–∞

### –î–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —Å–∫—Ä–∞–ø–µ—Ä–∞

1. –°—Ç–≤–æ—Ä—ñ—Ç—å –Ω–æ–≤–∏–π –∫–ª–∞—Å, —â–æ –Ω–∞—Å–ª—ñ–¥—É—î—Ç—å—Å—è –≤—ñ–¥ `BaseScraper`:

```python
from src.scrapers.base_scraper import BaseScraper

class MyScraper(BaseScraper):
    def __init__(self, **kwargs):
        defaults = {
            "base_url": "https://example.com",
            "user_agent": "my-scraper/1.0",
        }
        defaults.update(kwargs)
        super().__init__(**defaults)

    def scrape(self, start_url: str, max_pages: int = 0) -> List[Dict]:
        # –í–∞—à–∞ –ª–æ–≥—ñ–∫–∞ —Å–∫—Ä–∞–ø—ñ–Ω–≥—É
        pass
```

2. –î–æ–¥–∞–π—Ç–µ —Å–∫—Ä–∞–ø–µ—Ä —É `scripts/run_scraper.py`
3. –°—Ç–≤–æ—Ä—ñ—Ç—å –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏–π —Ñ–∞–π–ª —É `config/`

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–∏—Ö

–ö–æ–∂–µ–Ω —Å–∫—Ä–∞–ø–µ—Ä –ø–æ–≤–∏–Ω–µ–Ω –ø–æ–≤–µ—Ä—Ç–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–Ω–∏–∫—ñ–≤ –∑ —Ç–∞–∫–æ—é —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é:

```python
{
    "title": "–ù–∞–∑–≤–∞ –ø—Ä–æ–¥—É–∫—Ç—É",
    "url": "https://example.com/product",
    "snippet": "–û–ø–∏—Å –ø—Ä–æ–¥—É–∫—Ç—É",
    "image_url": "https://example.com/image.jpg",
    "price": 99.99,
    "currency": "–≥—Ä–Ω",
    "date_posted": "2024-01-01T00:00:00"  # ISO —Ñ–æ—Ä–º–∞—Ç
}
```

## –õ—ñ—Ü–µ–Ω–∑—ñ—è

MIT

## –ê–≤—Ç–æ—Ä

–í–∞—à–µ —ñ–º'—è / –í–∞—à–∞ –æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—è
