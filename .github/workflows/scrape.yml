name: Scheduled Scraping

on:
  schedule:
    # Запускаємо кожні 12 годин
    - cron: '0 */12 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Fora scraper
        run: |
          mkdir -p data
          python scripts/run_scraper.py --site fora --db data/listings.db

      - name: Export Fora data and log progress
        run: |
          python scripts/analyze.py --db data/listings.db --site fora --export-excel data/fora_listings.xlsx
          python scripts/monitor.py --db data/listings.db --site fora --log-progress

      - name: Run Novus scraper
        run: |
          mkdir -p data
          python scripts/run_scraper.py --site novus --db data/listings.db

      - name: Export Novus data and log progress
        run: |
          python scripts/analyze.py --db data/listings.db --site novus --export-excel data/novus_listings.xlsx
          python scripts/monitor.py --db data/listings.db --site novus --log-progress

      - name: Commit scraped data
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add data/*
          git diff-index --quiet HEAD || git commit -m 'Update scraped data and progress logs'
          git push
