name: Automated Ukrainian E-commerce Scraping

on:
  schedule:
    # 11:00 EET = 09:00 UTC, 23:00 EET = 21:00 UTC
    - cron: '0 9 * * *'   # 11:00 EET (—Ä–∞–Ω–æ–∫)
    - cron: '0 21 * * *'  # 23:00 EET (–≤–µ—á—ñ—Ä)
  workflow_dispatch:      # –†—É—á–Ω–∏–π –∑–∞–ø—É—Å–∫

jobs:
  scrape-sites:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        site: [fora, novus]
      fail-fast: false  # –ü—Ä–æ–¥–æ–≤–∂—É–≤–∞—Ç–∏ –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –æ–¥–∏–Ω —Å–∞–π—Ç –Ω–µ –ø—Ä–∞—Ü—é—î
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Create data directories
        run: |
          mkdir -p data/${{ matrix.site }} data/monitoring
          
      - name: Run scraper for ${{ matrix.site }}
        run: |
          python scripts/run_scraper.py \
            --site ${{ matrix.site }} \
            --historical \
            --config-dir config
        env:
          PYTHONPATH: ${{ github.workspace }}
          
      - name: Generate monitoring reports
        run: |
          python scripts/health_monitor.py
          python scripts/data_analyzer.py
          
      - name: Commit and push results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Actions Bot"
          
          # Add all data files
          git add data/
          
          # Only commit if there are changes
          if ! git diff --cached --quiet; then
            git commit -m "üìä Automated scraping results - ${{ matrix.site }} - $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
            git push
          else
            echo "No changes to commit"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: scraping-results-${{ matrix.site }}-${{ github.run_number }}
          path: |
            data/${{ matrix.site }}/
            data/monitoring/
            !data/**/*.db
          retention-days: 30
          
  consolidate-reports:
    needs: scrape-sites
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Checkout repository  
        uses: actions/checkout@v4
        
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install pandas openpyxl
          
      - name: Generate consolidated report
        run: |
          python -c "
          import json
          from datetime import datetime
          
          report = {
              'timestamp': datetime.now().isoformat(),
              'workflow_run': '${{ github.run_number }}',
              'status': 'completed',
              'sites_processed': ['fora', 'novus']
          }
          
          with open('data/monitoring/workflow_summary.json', 'w') as f:
              json.dump(report, f, indent=2)
          "
